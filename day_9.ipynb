{"cells":[{"cell_type":"markdown","metadata":{"id":"BVpNj_jqwFi0"},"source":["## Using APIs in Projects\n","\n","\n","When getting data from APIs, I strongly suggest following a three-step workflow:\n","\n","1. Write some code that gets data from an API and saves all of the data (if possible) to a file\n","2. Write a second program (usually a second file) that loads the data from the API, extracts the data that will be useful for analysis, and saves it in a flat file (typically a CSV).\n","3. Program number 3 loads the CSV file and does the analysis\n","\n","This approach has a few important benefits.\n","\n","The first and most important is that often it is difficult to get the same raw data again. If you are using Twitter, then the Search API only lets you get the last week. If you are doing analysis a month down the road and decide that you really wish you had saved metadata about the number of retweets, it is too late. By saving the raw data you can change your measures or analysis strategy and still have access to the data.\n","\n","The second is that this gives you a nice pipeline, with intermediate files. Instead of including the entire raw data file in the code that does analysis, you only have to load the CSV, which is often much smaller and easier to work with.\n","\n","This brief lesson will show an example of this workflow, using `tweepy`.\n","\n","Note that I'm going to put everything in one file for convenience, but my typical workflow is to put these in separate files and then run each file separately."]},{"cell_type":"markdown","metadata":{"id":"M6RfpuORwFi5"},"source":["## Program 1 - Data Retrieval\n","\n","The goal of our project is to produce a visualization of the histogram of the number of retweets for recent tweets about President Trump. The first program gets tweets about President Trump.\n","\n","Older versions of tweepy made it easier to get the JSON returned by "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"5oV4HIQuwFi6","executionInfo":{"status":"error","timestamp":1667282629436,"user_tz":240,"elapsed":241,"user":{"displayName":"Woojin Lee","userId":"07068616791095526586"}},"outputId":"8b95e927-1e76-459b-d391-4db53b96c39b"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8980247e907a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitter_authentication\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbearer_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'twitter_authentication'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import tweepy\n","import json\n","import requests\n","from twitter_authentication import bearer_token\n","import pandas as pd\n","import time\n","\n","client = tweepy.Client(bearer_token, \n","                       return_type=dict, # Without this, tweepy returns an object-based response\n","                       wait_on_rate_limit=True\n","                      )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzyZr2B_wFi7"},"outputs":[],"source":["with open('raw_trump_tweets.txt', 'w') as f: # By opening with 'a' (for append) we can write to this file again\n","                                            # e.g., if we need to restart data collection.\n","    num_tweets = 4000\n","    tweet_count = 0\n","    next_token = None\n","    \n","    while tweet_count < num_tweets:\n","        response = client.search_recent_tweets(\n","            query='Trump -is:retweet', \n","            user_fields = ['username', 'public_metrics', 'description', 'location'],\n","            tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n","            expansions = 'author_id',\n","            next_token = next_token,\n","            max_results=100)\n","        \n","        next_token = response['meta']['next_token'] # get the \"next token\", which gives us the next page\n","        tweets = response['data']\n","        tweet_count += len(tweets)\n","        \n","        f.write(json.dumps(response)+ '\\n') # Write each response's JSON as a new line\n","        time.sleep(.5)"]},{"cell_type":"markdown","metadata":{"id":"5tGRgcDewFi8"},"source":["## Program 2 - Data Cleaning\n","\n","This program loads the saved raw data, grabs what we want, and converts it into a pandas dataframe and a CSV.\n","\n","I decided to save the timestamp, text, and retweet and favorite counts, together with the public metrics about the author. Tweepy puts author info in an \"includes\" dictionary, so we have to extract it from there.\n","\n","This is also where you typically would do more complicated measure creation. Here I show how to create a measure of tweet_length."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYgLXCDTwFi9"},"outputs":[],"source":["with open('raw_trump_tweets.txt', 'r') as f:\n","    responses = []\n","    for line in f.readlines():\n","        responses.append(json.loads(line))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6uY5HdNwFi9"},"outputs":[],"source":["result = []\n","user_dict = {}\n","# Loop through each response object\n","for response in responses:\n","    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n","    for user in response['includes']['users']:\n","        user_dict[user['id']] = {'username': user['username'], \n","                              'followers': user['public_metrics']['followers_count'],\n","                              'tweets': user['public_metrics']['tweet_count']\n","                             }\n","    for tweet in response['data']:\n","        # For each tweet, find the author's information\n","        author_info = user_dict[tweet['author_id']]\n","        # Put all of the information we want to keep in a single dictionary for each tweet\n","        result.append({'author_id': tweet['author_id'], \n","                       'username': author_info['username'],\n","                       'author_followers': author_info['followers'],\n","                       'author_tweets': author_info['tweets'],\n","                       'text': tweet['text'],\n","                       'created_at': tweet['created_at'],\n","                       'retweets': tweet['public_metrics']['retweet_count'],\n","                       'likes': tweet['public_metrics']['like_count'],\n","                       'tweet_length': len(tweet['text'])\n","                      })\n","df = pd.DataFrame(result)\n","df.to_csv('cleaned_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"fKYpt9F9wFi-"},"source":["## Program 3 - Data Analysis\n","\n","Here we use pandas to load the data and analyze it. This could include statistical tests. Here, I'm just visualizing the distribution of retweets and the relationship between retweets and length."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-GkBs61SwFi_"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-7E0NhWwFjA"},"outputs":[],"source":["df = pd.read_csv('./cleaned_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9j71b_ASwFjA"},"outputs":[],"source":["# Just make sure it looks OK.\n","df.sort_values('retweets')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RxsZ3LUwFjB"},"outputs":[],"source":["sns.displot(df.retweets)"]},{"cell_type":"markdown","metadata":{"id":"rD1a_g1EwFjB"},"source":["As expected, it's super skewed, with most tweets never getting retweeted while a few get tons of retweets.\n","\n","Let's see if it changes if we get rid of the tweets that never got retweeted (like, maybe we have a principled reason to believe they are different than other tweets)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9glEcrYwFjC"},"outputs":[],"source":["sns.displot(df.loc[df.retweets > 1, 'retweets']);"]},{"cell_type":"markdown","metadata":{"id":"qbsc-EQEwFjC"},"source":["As I thought, this is a somewhat \"scale-free\" distribution, meaning wherever you zoom in, you see the same pattern. Try changing the `0` up above to any (small) number."]},{"cell_type":"markdown","metadata":{"id":"UCOy5xZ2wFjC"},"source":["For fun, let's also look at the relationship between retweets and tweet length."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxWm_1dNwFjC"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C6vSCzQSwFjD"},"outputs":[],"source":["sns.jointplot(y='retweets', x='tweet_length', data = df);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NL4MZF37wFjD"},"outputs":[],"source":["# Because retweets are so skewed, let's log them\n","p = sns.jointplot(y=np.log(df.retweets + 1), x='tweet_length', data = df)\n","p.set_axis_labels('Tweet Length','Retweets (log)');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgW_3QlpwFjD"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"teaching","language":"python","name":"teaching"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}